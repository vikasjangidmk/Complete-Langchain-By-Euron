{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Prompting with Examples \n",
    "Zero-Shot Prompting:\n",
    "Ask a task without examples.\n",
    "Example: \"Translate this to French: Hello.\"\n",
    "\n",
    "One-Shot Prompting:\n",
    "Provide one example before the task.\n",
    "Example:\n",
    "\"Translate: 'Hello -> Bonjour'. Now, translate: 'Goodbye'.\"\n",
    "\n",
    "Few-Shot Prompting:\n",
    "Provide a few examples to guide the model.\n",
    "Example:\n",
    "\"Translate: 'Hello -> Bonjour', 'Cat -> Chat'. Now, translate: 'Dog'.\"\n",
    "\n",
    "Chain-of-Thought Prompting:\n",
    "Encourage step-by-step reasoning.\n",
    "Example:\n",
    "\"Calculate: If 5 apples cost $10, what is the cost of 2 apples? Step-by-step, first find the cost of 1 apple...\"\n",
    "\n",
    "Role-Based Prompting:\n",
    "Assign a role to influence tone or expertise.\n",
    "Example:\n",
    "\"You are a teacher. Explain Python functions to beginners.\"\n",
    "\n",
    "Instruction-Based Prompting:\n",
    "Provide detailed instructions for specific output.\n",
    "Example:\n",
    "\"Summarize the text in 3 bullet points.\"\n",
    "\n",
    "Interactive Prompting:\n",
    "Use iterative inputs for clarification or refinement.\n",
    "Example:\n",
    "\"Rewrite this text to make it formal. If unclear, ask questions.\"\n",
    "\n",
    "Prompt Chaining:\n",
    "Break tasks into smaller parts.\n",
    "Example:\n",
    "\"First, generate a title. Then create an outline. Finally, write the content.\"\n",
    "\n",
    "Contextual Prompting:\n",
    "Provide relevant context for better responses.\n",
    "Example:\n",
    "\"Based on the given paragraph, summarize it in one sentence.\"\n",
    "\n",
    "Multimodal Prompting:\n",
    "Use text along with other inputs like images.\n",
    "Example:\n",
    "\"Describe the attached image in one sentence.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Prompt Engineering Tips (Short Version)\n",
    "Be Clear:\n",
    "Use specific and precise instructions. Example: \"Summarize in 2 sentences.\"\n",
    "\n",
    "Define Output Format:\n",
    "Request structured responses like bullet points, JSON, or HTML.\n",
    "\n",
    "Ask for a Self-Check:\n",
    "Add checks like: \"If unsure, respond with 'No information.'\"\n",
    "\n",
    "Use Delimiters or Tags:\n",
    "Separate instructions and context clearly to avoid confusion.\n",
    "\n",
    "Role Prompting:\n",
    "Assign a role to the model to adjust style and tone, e.g., \"Act as a mathematician.\"\n",
    "\n",
    "Limit Context:\n",
    "Use only the most relevant parts of a document to improve response accuracy.\n",
    "\n",
    "Show Examples:\n",
    "Provide examples to guide the model toward desired responses.\n",
    "\n",
    "Ask for Explanation:\n",
    "Request reasoning to improve accuracy, especially for logical tasks.\n",
    "\n",
    "Provide Step-by-Step Instructions:\n",
    "Include detailed steps or examples for better problem-solving.\n",
    "\n",
    "Split Tasks:\n",
    "Break complex tasks into smaller subtasks (prompt chaining) for more control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "How can I effectively prepare for my board exams?\n",
    "Example: 'Create a schedule for one week in a tabular format'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chatModel.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Here is an example of a sample schedule for preparing for board exams for one week:\\n\\n| Time      | Monday       | Tuesday   | Wednesday | Thursday   | Friday     | Saturday  | Sunday    |\\n|-----------|--------------|-----------|-----------|------------|------------|-----------|-----------|\\n| 8:00 AM   | Study       | Study     | Study     | Study      | Study      | Study     | Rest      |\\n| 10:00 AM  | Break       | Break     | Break     | Break      | Break      | Break     | Break     |\\n| 10:30 AM  | Practice    | Practice  | Practice  | Practice   | Practice   | Practice  | Practice  |\\n| 12:30 PM  | Lunch        | Lunch     | Lunch     | Lunch      | Lunch      | Lunch     | Lunch     |\\n| 1:30 PM   | Revision    | Revision  | Revision  | Revision   | Revision   | Revision  | Revision  |\\n| 3:30 PM   | Break        | Break     | Break     | Break      | Break      | Break     | Break     |\\n| 4:00 PM   | Mock Test   | Mock Test | Mock Test | Mock Test  | Mock Test  | Mock Test | Mock Test |\\n| 6:00 PM   | Dinner       | Dinner    | Dinner    | Dinner     | Dinner     | Dinner    | Dinner    |\\n| 7:00 PM   | Relax        | Relax     | Relax     | Relax      | Relax      | Relax     | Relax     |\\n\\nThis schedule includes time for studying, practicing, revising, taking mock tests, and also includes plenty of breaks, meals, and time for relaxation. It is important to customize this schedule based on your own study habits and preferences. Make sure to stay organized, stay focused, and stay consistent in your study routine. Good luck with your board exams!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 392, 'prompt_tokens': 33, 'total_tokens': 425, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BbOjAMdM4SMemziDssJQAxT1JsrJz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--287dfdf2-78be-4f2e-a69a-69681049f131-0' usage_metadata={'input_tokens': 33, 'output_tokens': 392, 'total_tokens': 425, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "How can I effectively prepare for my board exams?\n",
    "Example 1: 'Divide the syllabus into smaller parts and focus on one section at a time.'\n",
    "Example 2: 'Review past papers to get familiar with the exam pattern.'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 3: 'Create a study schedule and stick to it, allocating specific time slots for each subject.'\n",
      "Example 4: 'Seek help from teachers, tutors, or classmates when you have doubts or find certain topics challenging.'\n",
      "Example 5: 'Take short breaks in between study sessions to avoid burnout and keep your mind fresh.'\n",
      "Example 6: 'Practice solving sample papers and mock tests to improve your time management and problem-solving skills.'\n"
     ]
    }
   ],
   "source": [
    "response = chatModel.invoke(prompt)\n",
    "\n",
    "study_schedule = response.content\n",
    "print(study_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "What steps should I take to prepare borad exam you have to give fore maths , physics , chemisty in 2 days adn also give in computer plan give in tabular format\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Step                     | Action                                                                 |\n",
      "|--------------------------|------------------------------------------------------------------------|\n",
      "| Day 1: Morning          | Review all concepts in math, physics, and chemistry                    |\n",
      "| Day 1: Afternoon         | Solve practice problems and past exam papers for each subject          |\n",
      "| Day 1: Evening           | Review computer basics and important topics                            |\n",
      "| Day 2: Morning          | Take a mock exam for each subject to assess your understanding         |\n",
      "| Day 2: Afternoon         | Focus on weak areas identified during mock exams and review            |\n",
      "| Day 2: Evening           | Revise key formulas and concepts in math, physics, chemistry, and computer |\n"
     ]
    }
   ],
   "source": [
    "response = chatModel.invoke(prompt)\n",
    "\n",
    "study_schedule = response.content\n",
    "print(study_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"Translate the following English text to French: {text}\"\n",
    "prompt =PromptTemplate.from_template(prompt_template)\n",
    "formatted_prompt = prompt.format(text=\"Hello, I am Vikas Jangid?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Bonjour, je suis Vikas Jangid.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 25, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BbOlFLuETkZ4ds8Fwo8iBAPlvhyak', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--0dc20e4c-760c-4307-ac79-f09da1e3c2ef-0', usage_metadata={'input_tokens': 25, 'output_tokens': 10, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatModel.invoke(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ChatPromptTemplate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "chat_template= ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "        (\"system\", \"You are an {profession} expert on {topic}.\"),\n",
    "        (\"human\", \"Hello, Mr. {profession}, can you please answer a question?\"),\n",
    "        (\"ai\", \"Sure!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    profession=\"director do a moview\",\n",
    "    topic=\"funny movie \",\n",
    "    user_input=\"give some name of funny bollywood movie\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here are some popular and funny Bollywood movies:\n",
      "\n",
      "1. Andaz Apna Apna\n",
      "2. Hera Pheri\n",
      "3. Golmaal: Fun Unlimited\n",
      "4. Dhamaal\n",
      "5. Chupke Chupke\n",
      "6. Welcome\n",
      "7. Phir Hera Pheri\n",
      "8. Munna Bhai M.B.B.S\n",
      "9. Dhol\n",
      "10. Jaane Bhi Do Yaaro\n",
      "\n",
      "These movies are known for their humor and entertainment value. I hope you enjoy watching them!\n"
     ]
    }
   ],
   "source": [
    "response= chatModel.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    FewShotChatMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"hi!\", \"output\": \"¡hola!\"},\n",
    "    {\"input\": \"bye!\", \"output\": \"¡adiós!\"},\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "few_shot_prompt= FewShotChatMessagePromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an English-Spanish translator.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "input_text = \"Translate 'I am learning programming\"\n",
    "\n",
    "formatted_prompt = final_prompt.format(input=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an English-Spanish translator.\n",
      "Human: hi!\n",
      "AI: ¡hola!\n",
      "Human: bye!\n",
      "AI: ¡adiós!\n",
      "Human: Translate 'I am learning programming\n"
     ]
    }
   ],
   "source": [
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Estoy aprendiendo programación.\n"
     ]
    }
   ],
   "source": [
    "response= chatModel.invoke(formatted_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "examples = [\n",
    "    {\"input\": \"2+2\", \"output\": \"4\"},\n",
    "    {\"input\": \"2+3\", \"output\": \"5\"},\n",
    "    {\"input\": \"What is the capital of France?\", \"output\": \"Paris\"},\n",
    "    {\"input\": \"3*3\", \"output\": \"9\"},\n",
    "    {\"input\": \"Who wrote 'To Kill a Mockingbird'?\", \"output\": \"Harper Lee\"},\n",
    "    {\"input\": \"What is 10-4?\", \"output\": \"6\"},\n",
    "    {\"input\": \"5/5\", \"output\": \"1\"},\n",
    "    {\"input\": \"What is the largest planet in the solar system?\", \"output\": \"Jupiter\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    }
   ],
   "source": [
    "print(\"The End\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
