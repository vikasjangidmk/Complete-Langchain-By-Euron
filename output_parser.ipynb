{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f612c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fccaccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d2cc708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a921665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Give a user profile with name, age and city.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e454ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58e9e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "responce = chain.invoke({})  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69a97577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Sarah Johnson\n",
      "Age: 28\n",
      "City: New York City\n"
     ]
    }
   ],
   "source": [
    "print(responce.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cadde05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"What is the capital of {country}?\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "responce = chain.invoke({\"country\": \"India\"})  # type: ignore\n",
    "print(responce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f26a530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(responce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab1336fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do coders always mix up Christmas and Halloween?\n",
      "\n",
      "Because Oct 31 == Dec 25!\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}?\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "responce = chain.invoke({\"topic\": \"Coder\"})  # type: ignore\n",
    "print(responce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca217c7",
   "metadata": {},
   "source": [
    "# **JSON OUTPUT PARSER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b83cbb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'India', 'capital': 'New Delhi'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Extract the name of country and capital from the following text about a country.\n",
    "    Text: {country_info}\n",
    "    {format_instructions}\"\"\"\n",
    ")\n",
    "\n",
    "prompt = prompt_template.partial(format_instructions=format_instructions)\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "country_info = \"India is a country in South Asia. Its capital is New Delhi.\"\n",
    "responce = chain.invoke({\"country_info\": country_info})  # type: ignore\n",
    "\n",
    "print(responce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e3427",
   "metadata": {},
   "source": [
    "# **StructuredOutputParser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c05b4350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John', 'age': '30', 'city': 'San Francisco'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"name\", description=\"The name of the person\"),\n",
    "    ResponseSchema(name=\"age\", description=\"The age of the person\"),\n",
    "    ResponseSchema(name=\"city\", description=\"The city where the person lives\"),\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Extract information about a person from the following text.\n",
    "    Description: {person_description}\n",
    "    {format_instructions}\"\"\"\n",
    ")\n",
    "\n",
    "prompt = prompt_template.partial(format_instructions=format_instructions)\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "person_description = \"John is a 30-year-old software engineer living in San Francisco.\"\n",
    "\n",
    "response = chain.invoke({\"person_description\": person_description})  # type: ignore\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7444216",
   "metadata": {},
   "source": [
    "# **Pydentic Output Parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "161318de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "class Product(BaseModel):\n",
    "    name: str = Field(description=\"The name of the product\")\n",
    "    price: float = Field(description=\"The price of the product\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Product, format_instructions = \"Return a JSON object with the product details.\")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"Provide product details in JSON. \\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "prompt = prompt_template.partial(format_instructions=parser.get_format_instructions())\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "chain = prompt | llm | parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89a5fde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='iPhone 12' price=999.99\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d70d52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class WeatherInfo(BaseModel):\n",
    "    city: str\n",
    "    temperature: float\n",
    "    condition: str \n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=WeatherInfo)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Provide current weather info.\\n{format_instructions}\\nCity: {city}\",\n",
    "    input_variables=[\"city\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.3, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "920d6028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\AppData\\Local\\Temp\\ipykernel_30908\\839694582.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  raw_input= chain.run({\"city\": city_input})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"city\": \"Bangalore\",\n",
      "  \"temperature\": 27,\n",
      "  \"condition\": \"Partly Cloudy\"\n",
      "}\n",
      "city='Bangalore' temperature=27.0 condition='Partly Cloudy'\n"
     ]
    }
   ],
   "source": [
    "city_input = \"Bangalore\"\n",
    "\n",
    "raw_input= chain.run({\"city\": city_input})\n",
    "print(raw_input)\n",
    "print(parser.parse(raw_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0cd09d",
   "metadata": {},
   "source": [
    "# **Enum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea04bbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output: Blue\n",
      "Parsed output: Color.BLUE\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import EnumOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from enum import Enum\n",
    "\n",
    "class Color(Enum):\n",
    "    RED = \"red\"\n",
    "    GREEN = \"green\"\n",
    "    BLUE = \"blue\"\n",
    "    \n",
    "    \n",
    "parser = EnumOutputParser(enum=Color)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"What is your favorite color? \\n{format_instructions}\",\n",
    "    input_variables=[],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "output = model.invoke(prompt.format())  # type: ignore\n",
    "\n",
    "\n",
    "parsed = parser.parse(output.content.lower())\n",
    "print(f\"Raw output: {output.content}\")\n",
    "print(f\"Parsed output: {parsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "589c12bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-31 15:23:45.123456\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "parser = DatetimeOutputParser()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"What is the current date and time?\\n{format_instructions}\\n\",\n",
    "    input_variables=[],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "output = model.invoke(prompt.format())\n",
    "parsed = parser.parse(output.content)\n",
    "print(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdd22d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'orange']\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List three fruits.\\n{format_instructions}\\n\",\n",
    "    input_variables=[],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "model = ChatOpenAI(temperature=0)\n",
    "output = model.invoke(prompt.format())\n",
    "\n",
    "parsed = parser.parse(output.content)\n",
    "print(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b084270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    }
   ],
   "source": [
    "print(\"The End\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
