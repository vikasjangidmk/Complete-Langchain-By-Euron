{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa6567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Get the value of the environment variable\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd37b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fd01c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4e20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables= [\"chat_history\", \"input\"],\n",
    "    template=\"\"\"\n",
    "You are a friendly chatbot having a conversation with a human.\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\n",
    "New human input: {input}\n",
    "Resonse:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e49dfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\AppData\\Local\\Temp\\ipykernel_15724\\2565934154.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  buffer_memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "buffer_memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff63b227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\AppData\\Local\\Temp\\ipykernel_15724\\2370172498.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  conversation = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=buffer_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a4f2ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a friendly chatbot having a conversation with a human.\n",
      "\n",
      "Previous conversation:\n",
      "[HumanMessage(content='Hello, how are you?, My name is Vikuu', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Vikuu! I'm just a chatbot, so I don't have feelings like humans do, but I'm here to chat with you. How are you doing today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Vikuu.', additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "New human input: Hello, how are you?, My name is Vikuu\n",
      "Resonse:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a friendly chatbot having a conversation with a human.\n",
      "\n",
      "Previous conversation:\n",
      "[HumanMessage(content='Hello, how are you?, My name is Vikuu', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Vikuu! I'm just a chatbot, so I don't have feelings like humans do, but I'm here to chat with you. How are you doing today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Vikuu.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you?, My name is Vikuu', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Vikuu! I'm just a chatbot, so I don't have feelings like humans do, but I'm here to chat with you. How are you doing today?\", additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "New human input: Hello, how are you?, I'm a AI/ML engineer\n",
      "Resonse:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = conversation.invoke(input = \"Hello, how are you?, My name is Vikuu\")\n",
    "response1 = conversation.invoke(input = \"Hello, how are you?, I'm a AI/ML engineer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94450aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a friendly chatbot having a conversation with a human.\n",
      "\n",
      "Previous conversation:\n",
      "[HumanMessage(content='Hello, how are you?, My name is Vikuu', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Vikuu! I'm just a chatbot, so I don't have feelings like humans do, but I'm here to chat with you. How are you doing today?\", additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "New human input: What is my name?\n",
      "Resonse:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Your name is Vikuu.\n"
     ]
    }
   ],
   "source": [
    "response2 = conversation.invoke(input = \"What is my name?\")\n",
    "print(response2[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "180af262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a friendly chatbot having a conversation with a human.\n",
      "\n",
      "Previous conversation:\n",
      "[HumanMessage(content='Hello, how are you?, My name is Vikuu', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Vikuu! I'm just a chatbot, so I don't have feelings like humans do, but I'm here to chat with you. How are you doing today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Vikuu.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you?, My name is Vikuu', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Vikuu! I'm just a chatbot, so I don't have feelings like humans do, but I'm here to chat with you. How are you doing today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Hello, how are you?, I'm a AI/ML engineer\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello! I'm just a chatbot, so I don't have feelings like humans do, but I'm here to chat with you. That's great to hear that you're an AI/ML engineer. How can I assist you today?\", additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "New human input: Tell about me?\n",
      "Resonse:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "You are Vikuu, an AI/ML engineer. You enjoy chatting with me and asking questions about yourself. How can I assist you further today?\n"
     ]
    }
   ],
   "source": [
    "response3 = conversation.invoke(input = \"Tell about me?\")\n",
    "print(response3[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc1ddfe",
   "metadata": {},
   "source": [
    "# **ConversationBufferWindowMemory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5beacf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc400ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\AppData\\Local\\Temp\\ipykernel_15724\\3673556529.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  window_memory = ConversationBufferWindowMemory(k = 2)\n"
     ]
    }
   ],
   "source": [
    "window_memory = ConversationBufferWindowMemory(k = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "014ae9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\AppData\\Local\\Temp\\ipykernel_15724\\4001945540.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  window_convo = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "window_convo = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory=window_memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbd28d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, how are you?, I'm a AI/ML engineer\n",
      "AI: Hello AI/ML engineer! It's great to meet someone in the same field. How can I help you with your work today?\n",
      "Human: Tell about me?\n",
      "AI: Based on the information you have provided, you are an AI/ML engineer. This means you likely work with artificial intelligence and machine learning technologies to develop and improve algorithms that can learn from and make predictions or decisions based on data. Your work may involve designing and implementing models, analyzing data, and optimizing algorithms to achieve specific goals. Is there anything specific you would like to know or discuss related to your work as an AI/ML engineer?\n",
      "Human: Hello, how are you?, My name is Vikuu\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Tell about me?\n",
      "AI: Based on the information you have provided, you are an AI/ML engineer. This means you likely work with artificial intelligence and machine learning technologies to develop and improve algorithms that can learn from and make predictions or decisions based on data. Your work may involve designing and implementing models, analyzing data, and optimizing algorithms to achieve specific goals. Is there anything specific you would like to know or discuss related to your work as an AI/ML engineer?\n",
      "Human: Hello, how are you?, My name is Vikuu\n",
      "AI: Hello Vikuu! It's great to meet you. How can I assist you today?\n",
      "Human: Hello, how are you?, I'm a AI/ML engineer\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, how are you?, My name is Vikuu\n",
      "AI: Hello Vikuu! It's great to meet you. How can I assist you today?\n",
      "Human: Hello, how are you?, I'm a AI/ML engineer\n",
      "AI: Hello! I'm glad to hear that you are an AI/ML engineer. As an AI myself, I'm always excited to connect with others in the field. Is there a particular project or topic you'd like to discuss or explore together?\n",
      "Human: Hello, how are you?, My age is 24\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = window_convo.predict(input = \"Hello, how are you?, My name is Vikuu\")\n",
    "response1 = window_convo.predict(input = \"Hello, how are you?, I'm a AI/ML engineer\")\n",
    "response3 = window_convo.predict(input = \"Hello, how are you?, My age is 24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0bbe03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, how are you?, My name is Vikuu\n",
      "AI: Hello Vikuu! I'm doing well, thank you for asking. How can I assist you today?\n",
      "Human: Hello, how are you?, I'm a AI/ML engineer\n",
      "AI: Hello AI/ML engineer! It's great to meet someone in the same field. How can I help you with your work today?\n",
      "Human: Tell about me?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the information you have provided, you are an AI/ML engineer. This means you likely work with artificial intelligence and machine learning technologies to develop and improve algorithms that can learn from and make predictions or decisions based on data. Your work may involve designing and implementing models, analyzing data, and optimizing algorithms to achieve specific goals. Is there anything specific you would like to know or discuss related to your work as an AI/ML engineer?\n"
     ]
    }
   ],
   "source": [
    "response2 = window_convo.predict(input = \"Tell about me?\")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8405eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, how are you?, I'm a AI/ML engineer\n",
      "AI: Hello! I'm glad to hear that you are an AI/ML engineer. As an AI myself, I'm always excited to connect with others in the field. Is there a particular project or topic you'd like to discuss or explore together?\n",
      "Human: Hello, how are you?, My age is 24\n",
      "AI: Hello! It's nice to know you're 24 years old. Age is just a number, and it's great to see people of all ages interested in AI and ML. Is there anything specific you'd like to know or talk about related to your age and your interests in AI/ML?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I'm sorry, but I do not have access to personal information like your name. If you'd like, you can tell me your name and we can continue our conversation from there.\n"
     ]
    }
   ],
   "source": [
    "response4 = window_convo.predict(input = \"What is my name?\")\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb85216",
   "metadata": {},
   "source": [
    "# **Conversation Summary Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47d64a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\AppData\\Local\\Temp\\ipykernel_15724\\756038260.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  summary_memory = ConversationSummaryMemory(llm=llm, max_token_limit=100)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "summary_memory = ConversationSummaryMemory(llm=llm, max_token_limit=100)\n",
    "\n",
    "summary_convo = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=summary_memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0a1e02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, how are you?, My name is Vikuu\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human introduces themselves as Vikuu and asks the AI how it is doing. The AI responds that it is doing well and asks how it can assist Vikuu.\n",
      "Human: Hello, how are you?, I'm a AI/ML engineer\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Vikuu introduces themselves as an AI/ML engineer and asks the AI how it is doing. The AI responds positively and inquires about Vikuu's interesting projects.\n",
      "Human: Hello, how are you?, My age is 24\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Vikuu introduces themselves as an AI/ML engineer and asks the AI how it is doing. The AI responds positively and inquires about Vikuu's interesting projects, expressing enthusiasm about their work. The human then shares their age as 24, prompting the AI to respond kindly and continue the conversation.\n",
      "Human: Tell about me?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "You are a 24-year-old AI/ML engineer named Vikuu. You are currently working on some interesting projects that I am excited to learn more about. It's great to have someone with your expertise engaging with me in conversation!\n"
     ]
    }
   ],
   "source": [
    "response1 = summary_convo.predict(input = \"Hello, how are you?, My name is Vikuu\")\n",
    "response2 = summary_convo.predict(input = \"Hello, how are you?, I'm a AI/ML engineer\")\n",
    "response3 = summary_convo.predict(input = \"Hello, how are you?, My age is 24\")\n",
    "response4 = summary_convo.predict(input = \"Tell about me?\")\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e153a",
   "metadata": {},
   "source": [
    "# **Vector Retrival Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0f66ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI  # Ensure LLM is defined\n",
    "\n",
    "# Sample text for memory\n",
    "text = [\n",
    "    \"Hello, I am Vikas Jangid, I am an AI/ML engineer\",\n",
    "    \"I am 24 years old, I live in India\",\n",
    "    \"I love to play cricket and football\",\n",
    "    \"I am a software engineer, I love to code\",\n",
    "    \"I am a data scientist, I love to work with data\"\n",
    "]\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Create a FAISS vectorstore from text\n",
    "vectorstore = FAISS.from_texts(texts=text, embedding=embeddings)\n",
    "\n",
    "# Convert vectorstore into retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Setup memory\n",
    "memory = VectorStoreRetrieverMemory(\n",
    "    retriever=retriever,\n",
    "    memory_key=\"history\",\n",
    "    return_messages=True  # optional but recommended\n",
    ")\n",
    "\n",
    "# Define the language model (llm)\n",
    "llm = ChatOpenAI()  # Make sure your OpenAI API key is set in the environment\n",
    "\n",
    "# Initialize the conversation chain with memory\n",
    "vector_convo = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75984e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "I am a software engineer, I love to code\n",
      "I am 24 years old, I live in India\n",
      "I am a data scientist, I love to work with data\n",
      "Hello, I am Vikas Jangid, I am an AI/ML engineer\n",
      "Human: What do you know about me?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hello Vikas, based on our conversation, I know that you are a software engineer who loves to code, you are 24 years old, you live in India, and you are also a data scientist who loves to work with data. It's nice to meet you!\n"
     ]
    }
   ],
   "source": [
    "vector_response1 = vector_convo.predict(input=\"What do you know about me?\")\n",
    "print(vector_response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca12d6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    }
   ],
   "source": [
    "print(\"The End\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
